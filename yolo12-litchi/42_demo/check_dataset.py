#!/usr/bin/env python
# -*- coding: UTF-8 -*-
"""
æ£€æŸ¥æ•°æ®é›†è´¨é‡å’Œæ ‡æ³¨çš„è„šæœ¬
å¸®åŠ©è¯Šæ–­ä¸ºä»€ä¹ˆè¯†åˆ«ä¸å‡ºæ¥
"""
import os
import cv2
import numpy as np
from pathlib import Path
import yaml

def check_dataset_quality():
    """æ£€æŸ¥æ•°æ®é›†è´¨é‡å’Œæ ‡æ³¨"""
    
    # è¯»å–æ•°æ®é›†é…ç½®
    config_path = r"D:\æ ¡å†…\æ–°å»ºæ–‡ä»¶å¤¹\Finaldesign2.0\yolo12-litchi\ultralytics\cfg\datasets\A_DATA.yaml"
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except Exception as e:
        print(f"æ— æ³•è¯»å–é…ç½®æ–‡ä»¶: {e}")
        return
    
    dataset_path = config['path']
    train_images = os.path.join(dataset_path, config['train'])
    train_labels = os.path.join(dataset_path, config['segments_train'])
    
    print("=" * 60)
    print("æ•°æ®é›†è´¨é‡æ£€æŸ¥æŠ¥å‘Š")
    print("=" * 60)
    print(f"æ•°æ®é›†è·¯å¾„: {dataset_path}")
    print(f"è®­ç»ƒå›¾ç‰‡è·¯å¾„: {train_images}")
    print(f"è®­ç»ƒæ ‡ç­¾è·¯å¾„: {train_labels}")
    print(f"ç±»åˆ«æ•°é‡: {config['nc']}")
    print(f"ç±»åˆ«åç§°: {config['names']}")
    print()
    
    # æ£€æŸ¥å›¾ç‰‡å’Œæ ‡ç­¾æ–‡ä»¶
    if not os.path.exists(train_images):
        print(f"âŒ è®­ç»ƒå›¾ç‰‡è·¯å¾„ä¸å­˜åœ¨: {train_images}")
        return
    
    if not os.path.exists(train_labels):
        print(f"âŒ è®­ç»ƒæ ‡ç­¾è·¯å¾„ä¸å­˜åœ¨: {train_labels}")
        return
    
    # ç»Ÿè®¡æ–‡ä»¶æ•°é‡
    image_files = list(Path(train_images).glob("*.jpg")) + list(Path(train_images).glob("*.png"))
    label_files = list(Path(train_labels).glob("*.txt"))
    
    print(f"ğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
    print(f"   å›¾ç‰‡æ–‡ä»¶æ•°é‡: {len(image_files)}")
    print(f"   æ ‡ç­¾æ–‡ä»¶æ•°é‡: {len(label_files)}")
    
    if len(image_files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼")
        return
    
    if len(label_files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾æ–‡ä»¶ï¼")
        return
    
    # æ£€æŸ¥å›¾ç‰‡å°ºå¯¸åˆ†å¸ƒ
    print(f"\nğŸ“ å›¾ç‰‡å°ºå¯¸åˆ†æ:")
    sizes = []
    for img_file in image_files[:50]:  # åªæ£€æŸ¥å‰50å¼ 
        try:
            img = cv2.imread(str(img_file))
            if img is not None:
                h, w = img.shape[:2]
                sizes.append((w, h))
        except:
            continue
    
    if sizes:
        sizes = np.array(sizes)
        print(f"   å¹³å‡å°ºå¯¸: {sizes.mean(axis=0).astype(int)}")
        print(f"   æœ€å°å°ºå¯¸: {sizes.min(axis=0)}")
        print(f"   æœ€å¤§å°ºå¯¸: {sizes.max(axis=0)}")
        print(f"   å°ºå¯¸æ ‡å‡†å·®: {sizes.std(axis=0).astype(int)}")
    
    # æ£€æŸ¥æ ‡ç­¾è´¨é‡
    print(f"\nğŸ·ï¸ æ ‡ç­¾è´¨é‡åˆ†æ:")
    total_objects = 0
    class_counts = {}
    bbox_sizes = []
    
    for label_file in label_files[:100]:  # åªæ£€æŸ¥å‰100ä¸ªæ ‡ç­¾
        try:
            with open(label_file, 'r') as f:
                lines = f.readlines()
            
            for line in lines:
                parts = line.strip().split()
                if len(parts) >= 5:
                    class_id = int(parts[0])
                    # è§£æåˆ†å‰²ç‚¹ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                    coords = [float(x) for x in parts[1:]]
                    if len(coords) >= 6:  # è‡³å°‘3ä¸ªç‚¹
                        total_objects += 1
                        class_counts[class_id] = class_counts.get(class_id, 0) + 1
                        
                        # è®¡ç®—è¾¹ç•Œæ¡†å¤§å°
                        x_coords = coords[::2]
                        y_coords = coords[1::2]
                        if len(x_coords) >= 2 and len(y_coords) >= 2:
                            width = max(x_coords) - min(x_coords)
                            height = max(y_coords) - min(y_coords)
                            bbox_sizes.append((width, height))
        except Exception as e:
            print(f"   å¤„ç†æ ‡ç­¾æ–‡ä»¶ {label_file} æ—¶å‡ºé”™: {e}")
    
    print(f"   æ€»ç›®æ ‡æ•°é‡: {total_objects}")
    print(f"   å„ç±»åˆ«ç›®æ ‡æ•°é‡:")
    for class_id, count in sorted(class_counts.items()):
        class_name = config['names'][class_id] if class_id < len(config['names']) else f"æœªçŸ¥ç±»åˆ«{class_id}"
        print(f"     {class_name} (ID:{class_id}): {count}ä¸ª")
    
    if bbox_sizes:
        bbox_sizes = np.array(bbox_sizes)
        print(f"   ç›®æ ‡å°ºå¯¸ç»Ÿè®¡:")
        print(f"     å¹³å‡å°ºå¯¸: {bbox_sizes.mean(axis=0)}")
        print(f"     æœ€å°å°ºå¯¸: {bbox_sizes.min(axis=0)}")
        print(f"     æœ€å¤§å°ºå¯¸: {bbox_sizes.max(axis=0)}")
        
        # åˆ†æå¤§ç›®æ ‡æ¯”ä¾‹
        large_targets = np.sum((bbox_sizes > 0.3).any(axis=1))
        print(f"     å¤§ç›®æ ‡æ•°é‡ (>0.3): {large_targets} ({large_targets/len(bbox_sizes)*100:.1f}%)")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºæ ‡ç­¾æ–‡ä»¶
    empty_labels = 0
    for label_file in label_files:
        try:
            with open(label_file, 'r') as f:
                content = f.read().strip()
                if not content:
                    empty_labels += 1
        except:
            continue
    
    if empty_labels > 0:
        print(f"âš ï¸  å‘ç° {empty_labels} ä¸ªç©ºæ ‡ç­¾æ–‡ä»¶")
    
    # å»ºè®®
    print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    if len(image_files) < 100:
        print("   - æ•°æ®é›†è¾ƒå°ï¼Œå»ºè®®å¢åŠ æ›´å¤šè®­ç»ƒæ ·æœ¬")
    if bbox_sizes and bbox_sizes.mean() < 0.1:
        print("   - ç›®æ ‡å°ºå¯¸åå°ï¼Œå»ºè®®å¢åŠ æ›´å¤šå¤§ç›®æ ‡æ ·æœ¬")
    if large_targets/len(bbox_sizes) < 0.2:
        print("   - å¤§ç›®æ ‡æ ·æœ¬ä¸è¶³ï¼Œå»ºè®®å¢åŠ æ”¾å¤§å›¾ç‰‡çš„æ ‡æ³¨")
    print("   - ç¡®ä¿è®­ç»ƒæ—¶ä½¿ç”¨ imgsz=1536 æˆ–æ›´å¤§")
    print("   - ä½¿ç”¨å¢å¼ºè®­ç»ƒè„šæœ¬: step1_start_train_enhanced.py")

if __name__ == "__main__":
    check_dataset_quality()
